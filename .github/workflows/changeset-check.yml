name: Changeset Check

on:
  pull_request:
    branches:
      - dev
      - prev
      - main
  pull_request_target:
    types:
      - opened
      - synchronize
      - reopened
      - ready_for_review
      - edited
    branches:
      - dev
      - prev
      - main

concurrency:
  group: changeset-check-pr-${{ github.event.pull_request.number }}
  cancel-in-progress: true

permissions:
  contents: read
  issues: write
  pull-requests: write

jobs:
  changeset:
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Checkout
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd
        with:
          fetch-depth: 0

      - name: Detect changeset check scope
        id: scope
        shell: bash
        run: |
          set -euo pipefail
          is_cleanup_pr="false"
          cleanup_valid="false"
          cleanup_has_out_of_scope="false"
          project_touched="false"

          if [[ "${{ github.head_ref }}" == changeset-sync/* ]]; then
            is_cleanup_pr="true"
          fi

          git fetch origin "${{ github.base_ref }}" --depth=1
          changed="$(git diff --name-only "origin/${{ github.base_ref }}...HEAD" -- Project)"
          changed_status="$(git diff --name-status "origin/${{ github.base_ref }}...HEAD" -- Project)"
          echo "$changed"
          if [[ -n "$changed" ]]; then
            project_touched="true"
          fi

          requires_changeset="false"
          has_changeset_file="false"
          while IFS= read -r file; do
            [ -z "$file" ] && continue

            # Changeset files always require validation.
            if [[ "$file" == Project/.changeset/* ]]; then
              has_changeset_file="true"
              requires_changeset="true"
              continue
            fi

            # Docs-only paths are excluded from changeset validation.
            if [[ "$file" == Project/docs/* ]]; then
              continue
            fi
            if [[ "$file" == *.md || "$file" == *.mdx ]]; then
              continue
            fi

            requires_changeset="true"
          done <<< "$changed"

          if [[ "$is_cleanup_pr" == "true" ]]; then
            invalid="0"
            while IFS=$'\t' read -r status path_a path_b; do
              [ -z "${status:-}" ] && continue
              state="${status:0:1}"
              chosen_path="$path_a"
              if [[ "$state" == "R" || "$state" == "C" ]]; then
                chosen_path="$path_b"
              fi

              if [[ "$state" != "D" ]]; then
                invalid="1"
                continue
              fi
              if [[ "$chosen_path" == "Project/.changeset/README.md" ]]; then
                invalid="1"
                continue
              fi
              if [[ "$chosen_path" != Project/.changeset/*.md ]]; then
                invalid="1"
                continue
              fi
            done <<< "$changed_status"

            if [[ "$invalid" == "1" ]]; then
              cleanup_valid="false"
              cleanup_has_out_of_scope="true"
            else
              cleanup_valid="true"
              requires_changeset="false"
            fi
          fi

          echo "requires_changeset=$requires_changeset" >> "$GITHUB_OUTPUT"
          echo "has_changeset_file=$has_changeset_file" >> "$GITHUB_OUTPUT"
          echo "is_cleanup_pr=$is_cleanup_pr" >> "$GITHUB_OUTPUT"
          echo "cleanup_valid=$cleanup_valid" >> "$GITHUB_OUTPUT"
          echo "cleanup_has_out_of_scope=$cleanup_has_out_of_scope" >> "$GITHUB_OUTPUT"
          echo "project_touched=$project_touched" >> "$GITHUB_OUTPUT"

      - name: Setup Node
        if: steps.scope.outputs.requires_changeset == 'true' && steps.scope.outputs.is_cleanup_pr != 'true'
        uses: actions/setup-node@6044e13b5dc448c55e2357c09f80417699197238
        with:
          node-version: 24.13.1
          cache: pnpm
          cache-dependency-path: Project/pnpm-lock.yaml

      - name: Setup pnpm
        if: steps.scope.outputs.requires_changeset == 'true' && steps.scope.outputs.is_cleanup_pr != 'true'
        uses: pnpm/action-setup@41ff72655975bd51cab0327fa583b6e92b6d3061
        with:
          version: 10

      - name: Install
        if: steps.scope.outputs.requires_changeset == 'true' && steps.scope.outputs.is_cleanup_pr != 'true'
        run: pnpm -C Project install --frozen-lockfile

      - name: Skip docs-only changes
        if: steps.scope.outputs.requires_changeset != 'true' && steps.scope.outputs.is_cleanup_pr != 'true' && steps.scope.outputs.project_touched == 'true'
        run: echo "Docs-only changes detected in Project/. Skipping changeset validation."

      - name: Skip non-Project changes
        if: steps.scope.outputs.requires_changeset != 'true' && steps.scope.outputs.is_cleanup_pr != 'true' && steps.scope.outputs.project_touched != 'true'
        run: echo "No Project/ changes detected. Skipping changeset validation."

      - name: Validate cleanup-sync changeset scope
        if: steps.scope.outputs.is_cleanup_pr == 'true' && steps.scope.outputs.cleanup_valid == 'true'
        run: echo "Cleanup sync PR detected. Delete-only changeset scope is valid."

      - name: Verify changeset
        if: steps.scope.outputs.requires_changeset == 'true' && steps.scope.outputs.is_cleanup_pr != 'true'
        id: verify
        continue-on-error: true
        shell: bash
        run: |
          set +e
          output="$(NO_COLOR=1 FORCE_COLOR=0 pnpm -C Project exec changeset status --since=origin/${{ github.base_ref }} 2>&1)"
          code=$?
          {
            echo "exit_code=$code"
            echo "output<<EOF"
            echo "$output"
            echo "EOF"
          } >> "$GITHUB_OUTPUT"
          exit $code

      - name: Collect changeset inventory and bump math
        id: inventory
        if: always()
        shell: bash
        env:
          BASE_REF: ${{ github.base_ref }}
          IS_CLEANUP_PR: ${{ steps.scope.outputs.is_cleanup_pr }}
        run: |
          set -euo pipefail
          node <<'NODE'
          const fs = require("node:fs");
          const { execFileSync } = require("node:child_process");

          const MAX_FILE_LINES = 40;
          const MAX_PARSE_ERROR_LINES = 20;
          const PACKAGE_SUMMARY_LIMIT = 12;
          const BUMP_RANK = { none: 0, patch: 1, minor: 2, major: 3 };
          const RANK_TO_BUMP = ["none", "patch", "minor", "major"];

          const outputPath = process.env.GITHUB_OUTPUT;
          const baseRefName = (process.env.BASE_REF || "").trim();
          const baseRef = `origin/${baseRefName}`;
          const isCleanupPr = process.env.IS_CLEANUP_PR === "true";

          function runGit(args, allowFail = false) {
            try {
              return execFileSync("git", args, {
                encoding: "utf8",
                stdio: ["ignore", "pipe", "pipe"],
              }).trim();
            } catch (error) {
              if (allowFail) return "";
              throw error;
            }
          }

          function isChangesetMarkdown(filePath) {
            if (!filePath) return false;
            if (!filePath.startsWith("Project/.changeset/")) return false;
            if (!filePath.endsWith(".md")) return false;
            if (filePath === "Project/.changeset/README.md") return false;
            return true;
          }

          function listChangesetMarkdownFiles(ref) {
            const raw = runGit(["ls-tree", "-r", "--name-only", ref, "--", "Project/.changeset"], true);
            if (!raw) return [];
            return raw
              .split(/\r?\n/)
              .map((line) => line.trim())
              .filter((line) => isChangesetMarkdown(line))
              .sort((a, b) => a.localeCompare(b));
          }

          function listDeltaEntries(base, head) {
            const raw = runGit(["diff", "--name-status", `${base}...${head}`, "--", "Project/.changeset"], true);
            if (!raw) return [];

            const entries = [];
            for (const line of raw.split(/\r?\n/)) {
              if (!line.trim()) continue;
              const parts = line.split("\t");
              const statusToken = (parts[0] || "").trim();
              const status = statusToken.charAt(0);
              if (!status) continue;

              if (status === "R" || status === "C") {
                const oldPath = (parts[1] || "").trim();
                const newPath = (parts[2] || "").trim();
                if (!isChangesetMarkdown(oldPath) && !isChangesetMarkdown(newPath)) continue;
                entries.push({ status, oldPath, newPath });
                continue;
              }

              const filePath = (parts[1] || "").trim();
              if (!isChangesetMarkdown(filePath)) continue;
              entries.push({ status, path: filePath });
            }

            return entries;
          }

          function readFileAtRef(ref, filePath) {
            return runGit(["show", `${ref}:${filePath}`], false);
          }

          function readJsonAtRef(ref, filePath) {
            const raw = runGit(["show", `${ref}:${filePath}`], false);
            try {
              return JSON.parse(raw);
            } catch (error) {
              throw new Error(
                `invalid JSON in ${ref}:${filePath} (${error instanceof Error ? error.message : "unknown parse error"})`
              );
            }
          }

          function parseSemver(version) {
            const match = (version || "").trim().match(/^(\d+)\.(\d+)\.(\d+)$/);
            if (!match) {
              throw new Error(`unsupported stable version format: ${version || "(empty)"}`);
            }
            return {
              major: Number(match[1]),
              minor: Number(match[2]),
              patch: Number(match[3]),
            };
          }

          function bumpSemver(version, bump) {
            const parsed = parseSemver(version);
            if (bump === "major") {
              return `${parsed.major + 1}.0.0`;
            }
            if (bump === "minor") {
              return `${parsed.major}.${parsed.minor + 1}.0`;
            }
            if (bump === "patch") {
              return `${parsed.major}.${parsed.minor}.${parsed.patch + 1}`;
            }
            return `${parsed.major}.${parsed.minor}.${parsed.patch}`;
          }

          function parseChangesetFrontmatter(content) {
            const normalized = (content || "").replace(/\r\n/g, "\n");
            const match = normalized.match(/^---\n([\s\S]*?)\n---(?:\n|$)/);
            if (!match) {
              throw new Error("missing frontmatter block");
            }

            const entries = [];
            for (const rawLine of match[1].split("\n")) {
              const line = rawLine.trim();
              if (!line || line.startsWith("#")) continue;
              const parsed = line.match(/^["']?([^"':]+)["']?\s*:\s*(major|minor|patch|none)\s*$/i);
              if (!parsed) {
                throw new Error(`invalid frontmatter line: ${line}`);
              }
              const pkg = parsed[1].trim();
              const bump = parsed[2].toLowerCase();
              entries.push({ pkg, bump });
            }

            if (entries.length === 0) {
              throw new Error("no package bumps found in frontmatter");
            }

            return entries;
          }

          function accumulatePackageRanks(ref, files, scope) {
            const packageRanks = new Map();
            const parseErrors = [];

            for (const filePath of files) {
              let content;
              try {
                content = readFileAtRef(ref, filePath);
              } catch {
                parseErrors.push({ scope, filePath, reason: `unable to read ${ref}:${filePath}` });
                continue;
              }

              let parsedEntries;
              try {
                parsedEntries = parseChangesetFrontmatter(content);
              } catch (error) {
                parseErrors.push({
                  scope,
                  filePath,
                  reason: error instanceof Error ? error.message : "unknown parse error",
                });
                continue;
              }

              for (const { pkg, bump } of parsedEntries) {
                const rank = BUMP_RANK[bump];
                const current = packageRanks.get(pkg) ?? 0;
                if (rank > current) {
                  packageRanks.set(pkg, rank);
                }
              }
            }

            return { packageRanks, parseErrors };
          }

          function sortPackages(packageRanks) {
            return [...packageRanks.keys()].sort((a, b) => {
              if (a === "neon-conductor") return -1;
              if (b === "neon-conductor") return 1;
              return a.localeCompare(b);
            });
          }

          function totalBump(packageRanks) {
            let top = 0;
            for (const rank of packageRanks.values()) {
              if (rank > top) top = rank;
            }
            return RANK_TO_BUMP[top];
          }

          function packageSummary(packageRanks) {
            const sorted = sortPackages(packageRanks);
            if (sorted.length === 0) return "_none_";

            const shown = sorted.slice(0, PACKAGE_SUMMARY_LIMIT);
            const labels = shown.map((pkg) => `\`${pkg}=${RANK_TO_BUMP[packageRanks.get(pkg)]}\``);
            const remainder = sorted.length - shown.length;
            if (remainder > 0) {
              labels.push(`... +${remainder} more`);
            }
            return labels.join(", ");
          }

          function truncate(items, limit) {
            if (items.length <= limit) {
              return { shown: items, remaining: 0 };
            }
            return { shown: items.slice(0, limit), remaining: items.length - limit };
          }

          function formatFileList(files) {
            if (files.length === 0) return ["- _none_"];
            const { shown, remaining } = truncate(files, MAX_FILE_LINES);
            const lines = shown.map((filePath) => `- \`${filePath}\``);
            if (remaining > 0) {
              lines.push(`- ... +${remaining} more`);
            }
            return lines;
          }

          function formatDelta(entries) {
            if (entries.length === 0) return ["- _none_"];
            const { shown, remaining } = truncate(entries, MAX_FILE_LINES);
            const lines = shown.map((entry) => {
              if (entry.oldPath || entry.newPath) {
                return `- \`${entry.status}\` \`${entry.oldPath || "(missing)"}\` -> \`${entry.newPath || "(missing)"}\``;
              }
              return `- \`${entry.status}\` \`${entry.path}\``;
            });
            if (remaining > 0) {
              lines.push(`- ... +${remaining} more`);
            }
            return lines;
          }

          const baseFiles = listChangesetMarkdownFiles(baseRef);
          const headFiles = listChangesetMarkdownFiles("HEAD");
          const deltaEntries = listDeltaEntries(baseRef, "HEAD");
          const headFileSet = new Set(headFiles);
          const prOnlyFiles = [...new Set(
            deltaEntries
              .filter((entry) => entry.status !== "D")
              .map((entry) => (entry.newPath ? entry.newPath : entry.path))
              .filter((filePath) => isChangesetMarkdown(filePath) && headFileSet.has(filePath))
          )].sort((a, b) => a.localeCompare(b));

          const baseResult = accumulatePackageRanks(baseRef, baseFiles, `base:${baseRef}`);
          const headResult = accumulatePackageRanks("HEAD", headFiles, "pr-branch:HEAD");
          const prOnlyResult = accumulatePackageRanks("HEAD", prOnlyFiles, "pr-only:HEAD");

          const allParseErrors = [
            ...baseResult.parseErrors,
            ...headResult.parseErrors,
            ...prOnlyResult.parseErrors,
          ];

          const reportLines = [
            "### Found changeset files",
            "",
            `#### Base branch files (origin/${baseRefName})`,
            ...formatFileList(baseFiles),
            "",
            "#### PR branch files (post-merge snapshot)",
            ...formatFileList(headFiles),
            "",
            "#### PR delta vs base",
            ...formatDelta(deltaEntries),
            "",
            "### Total bump calculation",
            "",
            "- Bump precedence: `major > minor > patch > none`",
            `- Base total: \`${totalBump(baseResult.packageRanks)}\` (${packageSummary(baseResult.packageRanks)})`,
            `- PR-only total: \`${totalBump(prOnlyResult.packageRanks)}\` (${packageSummary(prOnlyResult.packageRanks)})`,
            `- Post-merge total: \`${totalBump(headResult.packageRanks)}\` (${packageSummary(headResult.packageRanks)})`,
          ];

          if (isCleanupPr) {
            reportLines.push(
              "",
              "### Cleanup sync mode",
              "",
              "- Cleanup PR detected: `yes`",
              "- Changeset bump validation is replaced by delete-only scope checks."
            );
          }

          reportLines.push("", "### Projected stable version", "");
          if (isCleanupPr) {
            reportLines.push("- Projection not shown for cleanup sync PR.");
          } else if (baseRefName === "dev" || baseRefName === "prev" || baseRefName === "main") {
            try {
              const stablePackage = readJsonAtRef("origin/main", "Project/package.json");
              const stableVersion = (stablePackage && stablePackage.version ? String(stablePackage.version) : "").trim();
              if (!stableVersion) {
                throw new Error("missing `version` in origin/main:Project/package.json");
              }

              const appliedBump = totalBump(headResult.packageRanks);
              const projectedVersion = bumpSemver(stableVersion, appliedBump);
              reportLines.push(`- Base branch context: \`${baseRefName}\``);
              reportLines.push(`- Baseline (origin/main): \`${stableVersion}\``);
              reportLines.push(`- Applied bump (post-merge): \`${appliedBump}\``);
              reportLines.push(`- Projected stable: \`${projectedVersion}\``);
              reportLines.push(`- Projected tag: \`v${projectedVersion}\``);
            } catch (error) {
              const reason = error instanceof Error ? error.message : "unknown projection error";
              reportLines.push(`- Projection unavailable: ${reason}`);
            }
          } else {
            reportLines.push(`- Projection not shown for base branch \`${baseRefName || "unknown"}\`.`);
          }

          if (allParseErrors.length > 0) {
            reportLines.push("", "### Unparsed files", "");
            const { shown, remaining } = truncate(allParseErrors, MAX_PARSE_ERROR_LINES);
            for (const err of shown) {
              reportLines.push(`- [${err.scope}] \`${err.filePath}\`: ${err.reason}`);
            }
            if (remaining > 0) {
              reportLines.push(`- ... +${remaining} more`);
            }
          }

          const report = reportLines.join("\n");
          fs.appendFileSync(outputPath, `report<<EOF\n${report}\nEOF\n`, "utf8");
          NODE

      - name: Upsert changeset comment
        if: always() && github.event.pull_request.head.repo.full_name == github.repository && (steps.scope.outputs.project_touched == 'true' || steps.scope.outputs.is_cleanup_pr == 'true')
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd
        env:
          REQUIRES_CHANGESET: ${{ steps.scope.outputs.requires_changeset }}
          HAS_CHANGESET_FILE: ${{ steps.scope.outputs.has_changeset_file }}
          IS_CLEANUP_PR: ${{ steps.scope.outputs.is_cleanup_pr }}
          CLEANUP_VALID: ${{ steps.scope.outputs.cleanup_valid }}
          CLEANUP_HAS_OUT_OF_SCOPE: ${{ steps.scope.outputs.cleanup_has_out_of_scope }}
          PROJECT_TOUCHED: ${{ steps.scope.outputs.project_touched }}
          VERIFY_EXIT_CODE: ${{ steps.verify.outputs.exit_code }}
          VERIFY_OUTPUT: ${{ steps.verify.outputs.output }}
          INVENTORY_REPORT: ${{ steps.inventory.outputs.report }}
        with:
          script: |
            const marker = "<!-- changeset-check-comment -->";
            const issue_number = context.payload.pull_request.number;
            const { owner, repo } = context.repo;
            const base = context.payload.pull_request.base.ref;
            const requiresChangeset = process.env.REQUIRES_CHANGESET === "true";
            const hasChangesetFile = process.env.HAS_CHANGESET_FILE === "true";
            const isCleanupPr = process.env.IS_CLEANUP_PR === "true";
            const cleanupValid = process.env.CLEANUP_VALID === "true";
            const cleanupHasOutOfScope = process.env.CLEANUP_HAS_OUT_OF_SCOPE === "true";
            const projectTouched = process.env.PROJECT_TOUCHED === "true";
            const verifyPassed = process.env.VERIFY_EXIT_CODE === "0";
            const inventoryReport =
              process.env.INVENTORY_REPORT || "### Found changeset files\n\n- _No inventory data captured._";
            const changesetGuide = [
              "### Changeset quick guide",
              "",
              "Use this format in `Project/.changeset/<name>.md`:",
              "",
              "```md",
              "---",
              "\"neon-conductor\": patch|minor|major|none",
              "---",
              "",
              "Short summary of the change for release notes.",
              "```",
              "",
              "When to use each bump:",
              "- `patch`: backwards-compatible bug fixes or small improvements",
              "- `minor`: backwards-compatible new features",
              "- `major`: breaking changes",
              "- `none`: no version bump for this package, but keep release note context",
            ].join("\n");

            const summaryLines = [
              marker,
              "## Changeset radar",
              "",
              `- Base branch: \`${base}\``,
              `- Requires changeset: ${requiresChangeset ? "yes" : "no"}`,
              `- Changeset detected: ${hasChangesetFile ? "yes" : "no"}`,
              `- Cleanup sync PR: ${isCleanupPr ? "yes" : "no"}`,
              `- Project paths changed: ${projectTouched ? "yes" : "no"}`,
            ];

            let body;
            if (isCleanupPr) {
              body = [
                ...summaryLines,
                "",
                inventoryReport,
                "",
                `- Result: ${cleanupValid ? "passed" : "failed"}`,
                "",
                cleanupValid
                  ? "Cleanup sync validation passed. Delete-only changeset scope is valid."
                  : cleanupHasOutOfScope
                    ? "Cleanup sync PR contains out-of-scope changes. Only delete operations under `Project/.changeset/*.md` are allowed."
                    : "Cleanup sync validation did not pass.",
                "",
                changesetGuide,
              ].join("\n");
            } else if (!requiresChangeset) {
              body = [
                ...summaryLines,
                "",
                inventoryReport,
                "",
                "- Result: skipped",
                "",
                "No changeset needed this round. Docs-only/non-release changes detected in `Project/`.",
                "",
                changesetGuide,
              ].join("\n");
            } else if (verifyPassed) {
              body = [
                ...summaryLines,
                "",
                inventoryReport,
                "",
                "- Result: passed",
                "",
                hasChangesetFile
                  ? "Changeset detected and validated. Nice work."
                  : "Changeset validation passed.",
                "",
                changesetGuide,
              ].join("\n");
            } else {
              const stripAnsi = (input) =>
                input
                  .replace(/\u001b\[[0-9;]*[A-Za-z]/g, "")
                  .replace(/\uFFFD\[[0-9;]*[A-Za-z]/g, "");
              const raw = stripAnsi(process.env.VERIFY_OUTPUT || "No output captured");
              const clipped =
                raw.length > 6000 ? `${raw.slice(0, 6000)}\n...truncated...` : raw;
              body = [
                ...summaryLines,
                "",
                inventoryReport,
                "",
                "- Result: failed",
                "",
                hasChangesetFile
                  ? "Changeset detected, but validation tripped on details."
                  : "Changeset required, but none was detected yet.",
                "",
                "```text",
                clipped,
                "```",
                "",
                changesetGuide,
              ].join("\n");
            }

            const comments = await github.paginate(github.rest.issues.listComments, {
              owner,
              repo,
              issue_number,
              per_page: 100,
            });

            const existing = comments.find((c) => (c.body || "").includes(marker));
            if (existing) {
              await github.rest.issues.updateComment({
                owner,
                repo,
                comment_id: existing.id,
                body,
              });
            } else {
              await github.rest.issues.createComment({
                owner,
                repo,
                issue_number,
                body,
              });
            }

      - name: Fail when changeset check fails
        if: steps.scope.outputs.requires_changeset == 'true' && steps.scope.outputs.is_cleanup_pr != 'true' && steps.verify.outputs.exit_code != '0'
        run: exit 1

      - name: Fail when cleanup sync scope is invalid
        if: steps.scope.outputs.is_cleanup_pr == 'true' && steps.scope.outputs.cleanup_valid != 'true'
        run: exit 1

  fork-comment:
    if: github.event_name == 'pull_request_target' && github.event.pull_request.head.repo.full_name != github.repository
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Upsert fork-safe changeset comment
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd
        with:
          script: |
            const marker = "<!-- changeset-check-comment -->";
            const issue_number = context.payload.pull_request.number;
            const { owner, repo } = context.repo;
            const base = context.payload.pull_request.base.ref;

            const files = await github.paginate(github.rest.pulls.listFiles, {
              owner,
              repo,
              pull_number: issue_number,
              per_page: 100,
            });

            let projectTouched = false;
            let requiresChangeset = false;
            let hasChangesetFile = false;
            for (const file of files) {
              const path = (file.filename || "").trim();
              if (!path.startsWith("Project/")) continue;
              projectTouched = true;

              if (path.startsWith("Project/.changeset/")) {
                if (path.endsWith(".md") && path !== "Project/.changeset/README.md") {
                  hasChangesetFile = true;
                  requiresChangeset = true;
                }
                continue;
              }

              if (path.startsWith("Project/docs/")) continue;
              if (path.endsWith(".md") || path.endsWith(".mdx")) continue;
              requiresChangeset = true;
            }

            let resultLine;
            let detailsLine;
            if (!projectTouched) {
              resultLine = "- Result: skipped";
              detailsLine = "No `Project/` changes detected.";
            } else if (!requiresChangeset) {
              resultLine = "- Result: skipped";
              detailsLine = "Docs-only changes detected in `Project/`; no changeset required.";
            } else if (hasChangesetFile) {
              resultLine = "- Result: precheck passed";
              detailsLine = "Changeset file detected for release-impacting `Project/` changes.";
            } else {
              resultLine = "- Result: precheck failed";
              detailsLine = "Changeset appears required but no `Project/.changeset/*.md` file was detected.";
            }

            const body = [
              marker,
              "## Changeset radar",
              "",
              `- Base branch: \`${base}\``,
              "- External fork PR: yes",
              `- Project paths changed: ${projectTouched ? "yes" : "no"}`,
              `- Requires changeset: ${requiresChangeset ? "yes" : "no"}`,
              `- Changeset detected: ${hasChangesetFile ? "yes" : "no"}`,
              resultLine,
              "",
              detailsLine,
              "",
              "Detailed release validation still runs in the PR checks; this comment is fork-safe metadata only.",
            ].join("\n");

            const comments = await github.paginate(github.rest.issues.listComments, {
              owner,
              repo,
              issue_number,
              per_page: 100,
            });

            const existing = comments.find((c) => (c.body || "").includes(marker));
            if (existing) {
              await github.rest.issues.updateComment({
                owner,
                repo,
                comment_id: existing.id,
                body,
              });
            } else {
              await github.rest.issues.createComment({
                owner,
                repo,
                issue_number,
                body,
              });
            }
